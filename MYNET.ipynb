{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch as tr\n",
    "from torch import nn\n",
    "import torch.optim as opt\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchmetrics.regression import MeanSquaredError, MeanAbsoluteError\n",
    "import pandas as pd\n",
    "import matplotlib as mt\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import typing\n",
    "from typing import Callable, Tuple\n",
    "import matplotlib as mt\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define device to use (cpu/gpu)\n",
    "if tr.cuda.is_available():\n",
    "  print('# of GPUs available: ', tr.cuda.device_count())\n",
    "  print('First GPU type: ',tr.cuda.get_device_name(0))\n",
    "device = ('cuda' if tr.cuda.is_available() else 'cpu')\n",
    "print(f\"Computation device: {device}\\n\")\n",
    "     \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning for universal linear embeddings of nonlinear dynamics “Koopman operator”\n",
    "\n",
    "In this work we try to replicate (and possibly improve) the results of the work done in this [PAPER](https://www.nature.com/articles/s41467-018-07210-0), in which they focus on developing DNN representations of Koopman eigenfunctions that remain interpretable and parsimonious, even for high-dimensional and strongly nonlinear systems.\n",
    "\n",
    "\n",
    "**Koopman operator:** <p>\n",
    "The Koopman operator is a linear operator that describes the evolution of scalar observables (i.e., measurement functions of the states) in an infinitedimensional Hilbert space. This operator theoretic point of view lifts the dynamics of a finite-dimensional nonlinear system to an infinite-dimensional function space where the evolution of the original system becomes linear, indeed, the eigenfunctions of the Koopman operator provide intrinsic coordinates that globally linearize the dynamics.\n",
    "\n",
    "\n",
    "**Dataset:** <p>\n",
    "All data can be reconstructed using the code available at [GIT](https://github.com/BethanyL/DeepKoopman).\n",
    "\n",
    "\n",
    "**Network architecture:** <p>\n",
    "\n",
    "We implement the original architecture of the above-mentioned paper, which will be discussed in detail below."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mathematical formulation of Koopman theory\n",
    "The object of the discussion are discrete-time dynamical systems:\n",
    "$$\\textbf{x}_{k+1} = \\textbf{F}(\\textbf{x}_k)$$\n",
    "where $\\textbf{x} \\in \\mathbb{R}^n $ is the state of the system and $\\textbf{F}$ represents the dynamics that map the state of the system forward in time. In the case of linear dynamics, the map $\\textbf{F}$ is a matrix that advances the state $\\textbf{x}$ and the dynamics of these linear systems admit a universal solution in terms of the eigenvalues and eigenvectors of the matrix $\\textbf{F}$. \\\\\n",
    "In 1931, B.O. Koopman provided an alternative description of dynamical systems in terms of the evolution of functions in the Hilbert space of possible measurements $\\textbf{g}(\\textbf{x})$ of the state. The so-called *Koopman operator*, $\\mathcal{K}$, that advances measurement functions is an infinite-dimensional linear operator such that\n",
    "\n",
    "$$\\mathcal{K}\\textbf{g} := \\textbf{g}\\ \\circ \\textbf{F}\\ \\ \\ \\text{i.e.}\\ \\ \\mathcal{K}\\textbf{g}(\\textbf{x}_k) = \\textbf{g}(\\textbf{x}_{k+1})$$\n",
    "\n",
    " Representing nonlinear dynamics in a linear framework, via the Koopman operator, has the potential to enable advanced nonlinear prediction using the theory developed for linear systems. However, obtaining finite-dimensional approximations of the infinite-dimensional Koopman operator has proven challenging in practical applications. In many approaches, they try to identify eigenfunctions of the Koopman operator directly, satisfying:\n",
    "\n",
    " $$\\varphi(\\textbf{x}_{k+1}) = \\mathcal{K} \\varphi(\\textbf{x}_k) = \\lambda \\varphi(\\textbf{x}_k).$$\n",
    "\n",
    " In practice, Koopman eigenfunctions may be more difficult to obtain than the solution of the discrete dynamics evolution equation we wrote in the begininning, however, these eigenfunctions are guaranteed to span an invariant subspace, and the Koopman operator will yield a matrix when restricted to this subspace, thus arriving at a description of the evolution of the system in terms of a finite dimensional linear operator."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Handling\n",
    "The authors of the study we are following found Koopman eigenfunctions in several example systems, including a simple model with a discrete spectrum and two examples that exhibit a continuous spectrum: the nonlinear pendulum and the high-dimensional unsteady fluid flow past a cylinder. They created the datasets by solving the systems of differential equations in MATLAB using the ode45 solver.\n",
    "\n",
    "For each dynamical system, they choose 5000 initial conditions for the test set, 5000 for the validation set, and 5000 - 20000 for the training set. For each initial condition, the differential equations were solved for some time span.\n",
    "\n",
    "We decided to not generate new data, but to import the ones they already used in order to compare the results. These datasets can be found in the above-mentioned github."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max number of initial conditions considered to make the train, validation, test datasets. If set to `None`, it takes all possible conditions \n",
    "max_initial_conditions=150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "option                           =4\n",
    "exp=[                            # Options: \n",
    "     \"DiscreteSpectrumExample\",  # 1)\n",
    "     \"FluidFlowBox\",             # 2)\n",
    "     \"FluidFlowOnAttractor\",     # 3)\n",
    "     \"Pendulum\"                  # 4)\n",
    "     ]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network architecture\n",
    "\n",
    "In this work they tried to identify only a *few key* intrinsic coordinates $\\textbf{y} = \\varphi(\\textbf{x})$ spanned by a set of Koopman eigenfunctions $\\varphi: \\mathbb{R}^p \\rightarrow \\mathbb{R}^n$, in the context of a dynamical system $\\textbf{y}_{k+1}=\\textbf{Ky}_k$. In particular, intrinsic coordinates which are useful in order to recostruct the dynamics are those for which $\\textbf{y} = \\varphi(\\textbf{x})$, hence, the state x can be recovered with the inverse $\\textbf{x} = \\varphi^{-1}(\\textbf{y})$ so that the state x may be recovered. This is achieved using an auto-encoder (in the following picture), where the action of $\\varphi$ is implemented by the encoder and the action of $\\varphi^{-1}$ by the decoder. The dimension p of the auto-encoder subspace is a hyperparameter of the network that the authors of the paper have chosen guided by knowledge of the system and subsequently tuned. So we decided to follow their choices.\n",
    "\n",
    "<img src=\"https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41467-018-07210-0/MediaObjects/41467_2018_7210_Fig1_HTML.png?as=webp\" style=\"width: 40%; margin-left: 30%; margin-right: 30%;\"/>\n",
    "\n",
    "The network have some hidden layer in the encoder and in the decoder whose number and width depends on the specific system. They are followed by an activation with the ReLU. The output layers of the encoder and the decoder are linear.\n",
    "\n",
    "Moreover, they generalized this framework to include a broad class of nonlinear systems that exhibit a continuous eigenvalue spectrum $\\lambda$. A continuous spectrum is characterized by a continuous range of observed frequencies, as opposed to the discrete spectrum consisting of isolated, fixed frequencies. This phenomena is observed in a wide range of physical systems that exhibit broadband frequency content, such as turbulence and nonlinear optics. The continuous spectrum spoils the simple Koopman descriptions, as there is not a straightforward finite approximation in terms of a small number of eigenfunctions. Indeed, away from the linear regime, an infinite Fourier sum is required to approximate the shift in frequency and eigenfunctions due to the non linearity.\n",
    "To deal with this problem, they allowed the eigenvalues of the matrix $\\textbf{K}$ to vary, parametrized by the function $\\lambda = \\Lambda(\\textbf{y})$, which is learned by an auxiliary network (in the following figure). The eigenvalues $\\lambda_{\\pm} = \\mu \\pm i \\omega$ are then used to parametrize block-diagonal $\\textbf{K}(\\mu,\\omega)$.\n",
    "In particular, they built separate auxiliary networks, one for the complex conjugate pair of eigenvalues and one for the the real eigenvalue. In this way, we can avoid to perform an infinite asymptotic expansion of the eigenfunctions. So, the resulting networks remain parsimonious, and the few key eigenfunctions are interpretable.\n",
    "\n",
    "<img src=\"https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41467-018-07210-0/MediaObjects/41467_2018_7210_Fig2_HTML.png?as=webp\" style=\"width: 40%; margin-left: 30%; margin-right: 30%;\"/>\n",
    "\n",
    "\n",
    "\n",
    "Also in this case, we have hidden layers whose number and dimension vary according to the specific system and the output layer is linear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if option not in range(1,5):\n",
    "    raise Exception(\"Option invalid, please stick with the option proposed...\")\n",
    "dataDir=\"./\"\n",
    "match exp[option-1]:\n",
    "    case \"DiscreteSpectrumExample\":\n",
    "        coor         =2                     # Number of generalized spatial coordinates of the experiment.\n",
    "        max_tr       =3                     # Number of files provided by the authors for training.\n",
    "        dimEncoder   =[30,30,2]             # Width of Encoder (first layer has input `coor` and is implied, last is dimension of Koopman space).\n",
    "        dimAuxNet    =[10,10,10]            # Width of Auxiliary Network for the continues parameters in K matrix \n",
    "                                            #   (first dimension is implied and is dimention of Koopman subspace considered, last is implied and is\n",
    "                                            #   the number of parameters needed to construct the Jordan Matrix)\n",
    "        RE_IMG_eigAux=(2,0)                 #   number of real eigenvalues in K Jordan matrix (1x1 blocks) and of complex eigenvalues (2x2 blocks).\n",
    "        numShift     =30                    # Considered lenght of trajectories.\n",
    "        lamb         =[0.1,0.1,1.0,1e-7]    # Relative weights of various loss contributions.\n",
    "        lamb_l2      =1e-15                 # L2 regularizing loss wheigt.\n",
    "        lr           =1e-3                  # Learning rate.\n",
    "        Dt           =0.02                  # Time scale of the experiment, rappresent the difference in time between two frame in trajectories.\n",
    "        lenTrj       =51                    # Lenght of integrated trajectory in the provided files.\n",
    "        batchSize    =256                   # Batch size (all computation on batch element are indipendent and parallelizable. \n",
    "                                            #   The loss and the metric results are taken as the mean on a batch.\n",
    "        \"\"\"\n",
    "        The Network geometry is: \n",
    "                                                                                                                        \n",
    "              Encoder                                           Decoder   \n",
    "            +-----------\\                                   ------------+\n",
    "            |         |\\ -----\\        K matrix         ---/  |         |\n",
    "            |         | \\      ----\\               ----/      |         |\n",
    "            |         |  \\          --------------/           |         |\n",
    "            |         |   \\           |         |             |         |\n",
    "            |         |    \\          |         |             |         |\n",
    "            |         |     \\         |         |             |         |\n",
    "            |         |      |        |         |             |         |\n",
    "            |         |      \\     -----------------          |         |\n",
    "            |         |    -------/   |        /    \\------   |         |\n",
    "            +-------------/    \\     /        /            \\------------+\n",
    "                       -\\       \\    |       /                           \n",
    "                         \\       \\   |      /                            \n",
    "                         \\       \\  |     /                             \n",
    "                          -\\      \\/    -/                              \n",
    "                            -------|   /                                \n",
    "                            |      |  /                                 \n",
    "                            |      | /                                  \n",
    "                            |      |/                                   \n",
    "                            +------/                                    \n",
    "                         Auxiliary net        \n",
    "        \n",
    "        The Encoder is constituted by `len(dimEncoder)` linear layers. All the layers except the last one are followed by a\n",
    "        ReLU activation layer for the non-linearity of the Encoder. The decoder as the same structure but reversed in order,\n",
    "        the first layer has not a ReLU applied at the input (that provide the dimention of the subspace of operators considered\n",
    "        in the Koopman space) and the output is in the phase space (has the same dimention that the input of the Encoder).\n",
    "        The K-matrix is a Jordan matrix block-diagonal in wich the real eigenvalues 1x1 blocks are parametrized by μ [exp(μ*Δt)],\n",
    "        the complex eigenvalues 2x2 blocks by μ, ω    exp(μ*Δt)*[[ cos(ω*Δt),-sin(ω*Δt)],\n",
    "                                                                 [ sin(ω*Δt), cos(ω*Δt)]]\n",
    "        in order to determine the values of μ and ω, there exist an Auxiliary Network constitued by `len(dimAuxNet)` linear layers\n",
    "        followed by a ReLU (except the last one).\n",
    "        \"\"\"\n",
    "        seqEncoder=(\n",
    "                    nn.Linear(coor          ,dimEncoder[0]),nn.ReLU(),\n",
    "                    nn.Linear(dimEncoder[0] ,dimEncoder[1]),nn.ReLU(),\n",
    "                    nn.Linear(dimEncoder[1] ,dimEncoder[2])\n",
    "                    )\n",
    "        seqDecoder=(\n",
    "                    nn.Linear(dimEncoder[2] ,dimEncoder[1]),nn.ReLU(),\n",
    "                    nn.Linear(dimEncoder[1] ,dimEncoder[0]),nn.ReLU(),\n",
    "                    nn.Linear(dimEncoder[0] ,coor         )\n",
    "                    )\n",
    "        auxNet    =(\n",
    "                    nn.Linear(dimEncoder[-1],dimAuxNet[0]),nn.ReLU(),\n",
    "                    nn.Linear(dimAuxNet[0]  ,dimAuxNet[1]),nn.ReLU(),\n",
    "                    nn.Linear(dimAuxNet[1]  ,dimAuxNet[2]),nn.ReLU(),\n",
    "                    nn.Linear(dimAuxNet[2]  ,1           )\n",
    "                    )\n",
    "    case \"FluidFlowBox\":\n",
    "        coor         =3\n",
    "        max_tr       =4\n",
    "        dimEncoder   =[130,3]\n",
    "        dimAuxNet    =[20,20]\n",
    "        RE_IMG_eigAux=(1,1)\n",
    "        numShift     =30\n",
    "        lamb         =[0.1,0.1,1.0,1e-9]\n",
    "        lamb_l2      =1e-13\n",
    "        lr           =1e-3\n",
    "        Dt           =0.01\n",
    "        lenTrj       =101\n",
    "        batchSize    =128\n",
    "        seqEncoder=(\n",
    "                    nn.Linear(coor          ,dimEncoder[0]),nn.ReLU(),\n",
    "                    nn.Linear(dimEncoder[0] ,dimEncoder[1])\n",
    "                    )\n",
    "        seqDecoder=(\n",
    "                    nn.Linear(dimEncoder[1] ,dimEncoder[0]),nn.ReLU(),\n",
    "                    nn.Linear(dimEncoder[0] ,coor         )\n",
    "                    )\n",
    "        auxNet    =(\n",
    "                    nn.Linear(dimEncoder[-1],dimAuxNet[0]),nn.ReLU(),\n",
    "                    nn.Linear(dimAuxNet[0]  ,dimAuxNet[1]),nn.ReLU(),\n",
    "                    nn.Linear(dimAuxNet[1]  ,1           )\n",
    "                    )\n",
    "\n",
    "    case \"FluidFlowOnAttractor\":\n",
    "        max_tr       =3\n",
    "        coor         =3\n",
    "        dimEncoder   =[105,2]\n",
    "        dimAuxNet    =[300]\n",
    "        RE_IMG_eigAux=(0,1)\n",
    "        numShift     =30\n",
    "        lamb         =[0.1,0.1,1.0,1e-7]\n",
    "        lamb_l2      =1e-13\n",
    "        lr           =1e-3\n",
    "        Dt           =0.05\n",
    "        lenTrj       =121\n",
    "        batchSize    =256\n",
    "        seqEncoder=(\n",
    "                    nn.Linear(coor          ,dimEncoder[0]),nn.ReLU(),\n",
    "                    nn.Linear(dimEncoder[0] ,dimEncoder[1])\n",
    "                    )\n",
    "        seqDecoder=(\n",
    "                    nn.Linear(dimEncoder[1] ,dimEncoder[0]),nn.ReLU(),\n",
    "                    nn.Linear(dimEncoder[0] ,coor         )\n",
    "                    )\n",
    "        auxNet    =(\n",
    "                    nn.Linear(dimEncoder[-1],dimAuxNet[0]),nn.ReLU(),\n",
    "                    nn.Linear(dimAuxNet[0]  ,1           )\n",
    "                    )\n",
    "\n",
    "    case \"Pendulum\":\n",
    "        max_tr       =6\n",
    "        coor         =2\n",
    "        dimEncoder   =[80,80,2]\n",
    "        dimAuxNet    =[170]\n",
    "        RE_IMG_eigAux=(0,1)\n",
    "        numShift     =30\n",
    "        lamb         =[0.001,0.001,1.0,1e-9]\n",
    "        lamb_l2      =1e-14\n",
    "        lr           =1e-3\n",
    "        Dt           =0.02\n",
    "        lenTrj       =51\n",
    "        batchSize    =128\n",
    "        seqEncoder=(\n",
    "                    nn.Linear(coor          ,dimEncoder[0]),nn.ReLU(),\n",
    "                    nn.Linear(dimEncoder[0] ,dimEncoder[1]),nn.ReLU(),\n",
    "                    nn.Linear(dimEncoder[1] ,dimEncoder[2])\n",
    "                    )\n",
    "        \n",
    "        seqDecoder=(\n",
    "                    nn.Linear(dimEncoder[2] ,dimEncoder[1]),nn.ReLU(),\n",
    "                    nn.Linear(dimEncoder[1] ,dimEncoder[0]),nn.ReLU(),\n",
    "                    nn.Linear(dimEncoder[0] ,coor         )\n",
    "                    )\n",
    "        auxNet    =(\n",
    "                    nn.Linear(dimEncoder[-1],dimAuxNet[0]),nn.ReLU(),\n",
    "                    nn.Linear(dimAuxNet[0]  ,1           )\n",
    "                    )\n",
    "    case EXP:\n",
    "        raise Exception(f\"Experiment Option not found.... [{EXP}]\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "filesTrain=[dataDir+exp[option-1]+\"_train\"+str(i)+\"_x.csv\" for i in range(1,max_tr+1)]\n",
    "fileVali=dataDir+exp[option-1]+\"_val_x.csv\"\n",
    "fileTest=dataDir+exp[option-1]+\"_test_x.csv\"\n",
    "print(\"Experiment\",exp[option-1]+\", files train:\")\n",
    "for f in filesTrain:\n",
    "    print(\"\\t\\t\"+f)\n",
    "print(\"\\nFile Validation:\\t\",fileVali)\n",
    "print(\"File Test:\\t\\t\",fileTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class customDataSet(Dataset):\n",
    "    '''\n",
    "    Dataset used to train validate and test the model, \n",
    "        it is array-like (can be subscripted) and its i-th element is a trajectory constitued by `Nshift` elements\n",
    "    '''\n",
    "    def __init__(self, filenames: str|list[str], coor: int, Nshift: int, lenTraje: int, debug: bool = False) -> None:\n",
    "        '''\n",
    "        `filenames` indicates a filename or a list of filenames where the data is stored. If provided a list of names it will concat the content.\n",
    "        `coor`      indicates the number of coordinates of the phase space trajectories.\n",
    "        `Nshit`     indicates the lenght of the trajectories to be considered (it must be <= than `lenTraje`)\n",
    "        `lenTraje`  is the lenght of the trajectories in the csv file (generated by integration algorithms)\n",
    "        `debug`     if set to True add a private attribute to the class named _dataPD, and it's a pandas DataFrame containing all the data read.\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self._data=tr.Tensor([])\n",
    "        self._Nshift=Nshift\n",
    "        self._coor=coor\n",
    "        self._event4file=[]\n",
    "        names=[\"x_\"+str(i) for i in range(coor)]\n",
    "        multiplefiles=False\n",
    "        if isinstance(filenames,list):\n",
    "            L=len(filenames)\n",
    "            if L>1:\n",
    "                multiplefiles=True\n",
    "            else:\n",
    "                filenames=filenames[0]\n",
    "        if multiplefiles:\n",
    "            self._dataPD=pd.concat([pd.read_csv(f,header=None,names=names) for f in filenames])\n",
    "        else:\n",
    "            self._dataPD=pd.read_csv(filenames,names=names) \n",
    "        \n",
    "        if (lenTraje<self._Nshift):\n",
    "            raise Exception(f\"Trajectories in file is lenTraje={lenTraje} long, but you want to extract {self._Nshift} time steps\")\n",
    "        IC=len(self._dataPD)//lenTraje\n",
    "        for i in range(IC if max_initial_conditions==None or IC<max_initial_conditions else max_initial_conditions):\n",
    "            tmp=[tr.tensor(self._dataPD[i*lenTraje+j:i*lenTraje+j+self._Nshift+1].values).unsqueeze(0).float() for j in range(lenTraje-self._Nshift-1)]\n",
    "            self._data=tr.cat((self._data,*tmp)) # This will put as fist dimention the time-shift, the second the batch and third the coordinates\n",
    "\n",
    "        if not debug:\n",
    "            self._dataPD=None\n",
    "\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        '''\n",
    "        return the number of initial conditions aka the number of trajectories considered (the length of them are `Nshift`) \n",
    "        '''\n",
    "        return len(self._data)\n",
    "\n",
    "    def __getitem__(self,i: int) -> tr.tensor:\n",
    "        '''\n",
    "        return the trajectory with i-th initial conditions\n",
    "        N.B. if `lenTraje` > `Nshift` and i-th initial condition is multiple of `lenTraje` (a true different trajectory)\n",
    "             the (i+1)-th initial condition will be i-th trajectory shifted in future by one time-frame\n",
    "        '''\n",
    "        return self._data[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create the datasets for training, validate and test the model using the files listed above  ^ ^ ^\n",
    "DATA_TR=customDataSet(filesTrain,coor,numShift,lenTrj)\n",
    "DATA_VL=customDataSet(fileVali  ,coor,numShift,lenTrj)\n",
    "DATA_TS=customDataSet(fileTest  ,coor,numShift,lenTrj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the datasets we create DataLoaders that group our datasets in batch\n",
    "train=DataLoader(DATA_TR,batch_size=batchSize,shuffle=True ,drop_last=True)\n",
    "vali =DataLoader(DATA_TR,batch_size=batchSize,shuffle=True ,drop_last=True)\n",
    "test =DataLoader(DATA_TR,batch_size=batchSize,shuffle=False,drop_last=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function\n",
    "The loss function they decided to use (and obviously the architecture itself) enforces constraints specifically designed to extract the fewest meaningful eigenfunctions; it consists of three weighted mean-squared error components: a reconstruction loss $\\mathcal{L}_{recon}$, included in order to obtain a good reconstruction accuracy of the auto-encoder, the loss future state prediction $\\mathcal{L}_{pred}$, necessary to have intrinsic coordinates that allow future state prediction,  linearity of dynamics loss $\\mathcal{L}_{lin}$, which enforces linear prediction over m time steps. They also use a $\\mathcal{L}_{\\infty}$\n",
    " term to penalty the data point with the largest loss. They also add $ℓ_2$\n",
    " regularization on the weights W to reduce overfitting. We decided to not do that because and we simply thought to make the weights smaller by adding a weight decay to Adam. However, as pointed out in [this paper](https://openreview.net/pdf?id=rk6qdGgCZ), the two things do not coincide, but we still found it effective in reducing overfitting. Their loss is:\n",
    " $$ \\mathcal{L} = \\alpha_1 (\\mathcal{L}_{recon} + \\mathcal{L}_{pred}) + \\mathcal{L}_{lin} + \\alpha_2 \\mathcal{L}_{\\infty} + \\alpha_3 ||\\textbf{W}||^2_2$$\n",
    " \n",
    " $$ \\mathcal{L}_{recon} = ||\\textbf{x}_1 - \\varphi^{-1}(\\varphi(\\textbf{x}_1))||_{\\text{MSE}}$$\n",
    " $$ \\mathcal{L}_{pred} = \\frac{1}{S_p} \\sum_{m=1}^{S_p} ||\\textbf{x}_{m+1} -  \\varphi^{-1}(K^m \\varphi(\\textbf{x}_1))||_{\\text{MSE}}$$\n",
    " $$ \\mathcal{L}_{lin} = \\frac{1}{T - 1} \\sum_{m=1}^{T-1} ||\\varphi(\\textbf{x}_{m+1}) - K^m \\varphi(\\textbf{x}_1)||_{\\text{MSE}}$$\n",
    "  $$ \\mathcal{L}_{\\infty} = ||\\textbf{x}_1 - \\varphi^{-1}(\\varphi(\\textbf{x}_1))||_{\\infty} + ||\\textbf{x}_2 - \\varphi^{-1}(K\\varphi(\\textbf{x}_1))||_{\\infty}$$\n",
    "  where $\\text{MSE}$ refers to mean squared error and T is the number of time steps in each trajectory. The weights $\\alpha_1$, $\\alpha_2$, and $\\alpha_3$ are hyperparameters which are different for each example. The integer $S_p$ is a hyperparameter for how many steps to check in the prediction loss. In our case we do not have the term proportional to $|| W ||_2^2|| $ and the weight decay was set equal to $\\alpha_3$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLoss(nn.Module):\n",
    "    '''\n",
    "    The loss proposed in the paper was made up of 5 differents conponents.\n",
    "    - The first one is needed for the reconstruction part. It is computed using MSELoss between the fist frame of a trajectory and the same encoded and decoded without\n",
    "        using the K-matrix to evolve temporally the frame (it will impose that the autoencoder part approximates the identity transformation, so the encoding\n",
    "        transformation could be interpreted as a geometric non-linear change of basis).\n",
    "    - The second one is responsable for the prediction power of the Network, it will compare the frame shifted in time (taking a frame in the trajectory evolved from the\n",
    "        point considered) with the same encoded, evolved in the Koopman subspace applying different times the Jordan matrix and than decoded.\n",
    "    - The third has to impose the linearity of the tranformation that evolve in time the system (tring to decouple the geometric transformation and the evolving in time).\n",
    "        it is made applying MSELoss between the true encoded version of a frame in a trajectory in Koopman subspace, and the same evolved from the first point (it is\n",
    "        similar to the second one but applied in Koopman subspace).\n",
    "    - The fourth is the L∞ norm between a point and his encoded-decoded version, and between a point shifted one frame i the future and his prediction.\n",
    "    The last contribution is the L2 regularisation of the wheigts. It is needed to avoid overfitting and to limit the value of wheigts to be near 0, to use at his best\n",
    "    the non-linearity of the model. We choose to implement this regularisation using a `weight_decay` for Adam Optimizer, as standard procedure for regularize weights in\n",
    "    pytorch. This method it's almost identical to L2 regularisation (the contribution in the loss is proportional to the magnitude of the weight), but we found out there\n",
    "    are some differences highlighted in a paper found at link https://openreview.net/pdf?id=rk6qdGgCZ    \n",
    "    '''\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.loss_reco=nn.MSELoss()\n",
    "        self.loss_pred=nn.MSELoss()\n",
    "        self.loss_line=nn.MSELoss()\n",
    "        self.loss_linf: Callable[[tr.tensor,tr.tensor,tr.tensor,tr.tensor],tr.tensor]=\\\n",
    "            lambda x,y,x1,y1: ((x-y).abs().max(dim=-1)[0]+(x1-y1).abs().max(dim=-1)[0]).mean()\n",
    "\n",
    "    #XT contiene i veri evoluti temporali a partire dal dato x, YT quelli predetti\n",
    "    def forward(self, XT: tr.tensor, YT: tr.tensor, phiT: tr.tensor, phiPredT: tr.tensor) -> tr.tensor:\n",
    "        return self.loss_reco(XT[0],YT[0]) * lamb[0]+self.loss_pred(XT[1:],YT[1:]) * lamb[1] + self.loss_line(phiT[1:],phiPredT[1:]) * lamb[2] + self.loss_linf(XT[0],YT[0],XT[1],YT[1]) * lamb[3]\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metric   = MeanSquaredError()\n",
    "metric   = MeanAbsoluteError() # As metric we wanted to use the MAE between a point evolved one time in the future and his prediction done by the Net\n",
    "loss     = CustomLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    '''\n",
    "    This the implementation of the Encoder\n",
    "    '''\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.layers=nn.Sequential(*seqEncoder)\n",
    "    def forward(self,x: tr.tensor) -> tr.tensor:\n",
    "        return self.layers(x)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    '''\n",
    "    This the implementation of the Decoder\n",
    "    '''\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.layers=nn.Sequential(*seqDecoder)\n",
    "    def forward(self,x: tr.tensor) -> tr.tensor:\n",
    "        return self.layers(x)\n",
    "\n",
    "\n",
    "#==================================================================================================\n",
    "#--------------------------------------------------------------------------------------------------\n",
    "#==================================================================================================\n",
    "\n",
    "class REAL_AuxNet(nn.Module):\n",
    "    '''\n",
    "    The Auxiliary Net provide the parametrization of one real value, but we need different parameters according\n",
    "    to the block that we want to construct. `REAL_AuxNet` provide one parameters: μ\n",
    "    '''\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.layers=nn.Sequential(*auxNet)\n",
    "    def forward(self,x: tr.tensor) -> tr.tensor:\n",
    "        return self.layers(x)\n",
    "        \n",
    "class COMPLEX_AuxNet(nn.Module):\n",
    "    '''\n",
    "    The Auxiliary Net provide the parametrization of one real value, but we need different parameters according\n",
    "    to the block that we want to construct. `COMPLEX_AuxNet` provide, using two `REAL_AuxNet`, the parameters μ, ω\n",
    "    '''\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        # Real part parameter μ AuxNet\n",
    "        self.AuxR=REAL_AuxNet()\n",
    "        # Immaginary part parameter ω AuxNet\n",
    "        self.AuxI=REAL_AuxNet()\n",
    "    def forward(self,x: tr.tensor) -> tr.tensor:\n",
    "        return self.AuxR(x), self.AuxI(x)\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------\n",
    "#--------------------------------------------------------------------------------------------------\n",
    "\n",
    "class _RealEntry(nn.Module):\n",
    "    '''\n",
    "    `_RealEntry` takes as input `Dt` (difference in time between two adiacent frames), the tensor from witch extract the information to determine\n",
    "    the value of the continuous parameters. It outputs a block 1x1.\n",
    "    '''\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        # Number of Real 1x1 blocks\n",
    "        self._NReal=RE_IMG_eigAux[0]\n",
    "        # Total width of Jordan matrix (n rows and n of columns)\n",
    "        self.n=self._NReal+RE_IMG_eigAux[1]*2\n",
    "\n",
    "        # Modules to generate all the needed parameters for real blocks\n",
    "        for i in range(self._NReal):\n",
    "            self.add_module(str(i),REAL_AuxNet())\n",
    "\n",
    "    def forward(self,indexBlock: int,x: tr.tensor,Dt: float) -> tr.tensor:\n",
    "        u=getattr(self,str(indexBlock) )(x)\n",
    "        # -------------- Block\n",
    "        R=tr.exp(u*Dt)\n",
    "        # --------------------\n",
    "        return R\n",
    "\n",
    "\n",
    "class _JordanBlock(nn.Module):\n",
    "    '''\n",
    "    `_JordanBlock` takes as input `Dt` (difference in time between two adiacent frames), the tensor from which extract the information to determine\n",
    "    the value of the continuous parameters. It outputs a block 2x2 as an array of dimension 4+(`n`-2) with 2 entries with true parameters,\n",
    "    (`n`-2) zeros padded and other 2 entries. This is because for technical reasons we preferred to compose the Jordan matrix starting from an array\n",
    "    with lenght n*n made of the blocks concatenated, reshaped to a \"n x n\" tensor.\n",
    "    '''\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        # Number of Complex 2x2 blocks\n",
    "        self._NComplex=RE_IMG_eigAux[1]\n",
    "        # Total width of Jordan matrix (n rows and n of columns)\n",
    "        self.n=RE_IMG_eigAux[0]+self._NComplex*2\n",
    "\n",
    "        # Modules to generate all the needed parameters for complex blocks\n",
    "        for i in range(self._NComplex):\n",
    "            self.add_module(str(i),COMPLEX_AuxNet())\n",
    "        # Register buffer to move it with model from CPU to GPU\n",
    "        self.register_buffer('_PAD', tr.zeros((batchSize,self.n-2),requires_grad=True))\n",
    "\n",
    "    def forward(self,indexBlock: int,x: tr.tensor,Dt: float) -> tr.tensor:\n",
    "        u,w=getattr(self,str(indexBlock) )(x)\n",
    "        R=tr.exp(u*Dt)\n",
    "        padd=PAD=getattr(self, '_PAD')\n",
    "        # -------------- Block\n",
    "        Block=tr.cat([R*tr.cos(w*Dt),-R*tr.sin(w*Dt),padd,R*tr.sin(w*Dt),R*tr.cos(w*Dt)],dim=-1) \n",
    "        # --------------------\n",
    "        return Block\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------\n",
    "#--------------------------------------------------------------------------------------------------\n",
    "\n",
    "class customMatrix(nn.Module):\n",
    "    '''\n",
    "    This Net will merge the various Jordan Blocks and compose the torch tensor representing the matrix. The blocks are composed choosing the real\n",
    "    parameters starting from the point in Koopman subspace of my system (the output of the decoder).\n",
    "    '''\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        # We store the number of real and complex blocks\n",
    "        self._NReal,self._NComplex=RE_IMG_eigAux\n",
    "        # We compute the width of the matrix\n",
    "        self.n=self._NReal+self._NComplex*2\n",
    "        # We store the required Networks to fix the parameters of the matrix\n",
    "        if self._NComplex>0: self._JB=_JordanBlock()\n",
    "        if self._NReal>0:    self._RE=_RealEntry()\n",
    "        # Register buffer to move it with model from CPU to GPU\n",
    "        self.register_buffer('_PAD', tr.zeros((self.n,batchSize),requires_grad=True))\n",
    "        \n",
    "    def forward(self,x,Dt):\n",
    "        if self.n != len(x[0]):\n",
    "            raise Exception(f\"Jordan Koopman matrix has dimension {self.n}x{self.n} but input has dimension {len(x[0])}....\")\n",
    "\n",
    "        # Here we'll store the tensor, from now it will contain the list of blocks to concat\n",
    "        matrixlist=[]\n",
    "\n",
    "        for i in range(self.n):\n",
    "            for j in range(self.n):\n",
    "                addedBlock=False\n",
    "                # The matrix is built putting first the complex blocks on the diagonal\n",
    "                if i==j and i%2==0 and i<self._NComplex*2:                  #        |\n",
    "                    #COMPLEX BLOCKS                                         #        |\n",
    "                    B=self._JB(i//2,x,Dt).T                                 #        | \n",
    "                    matrixlist.append(B)                                    #        |  \n",
    "                    addedBlock=True                                         #        |  \n",
    "                                                                            #        /  \n",
    "                # Then the real blocks  <-------------------------__________________/\n",
    "                elif i==j and i >=self._NComplex*2:\n",
    "                    #REAL BLOKS\n",
    "                    B=self._RE(i-self._NComplex*2,x,Dt).T\n",
    "                    matrixlist.append(B)\n",
    "                    addedBlock=True\n",
    "\n",
    "                if addedBlock:\n",
    "                    # We Padd with zeros between blocks to center them in the diagonal after the reshape\n",
    "                    PAD=getattr(self, '_PAD')\n",
    "                    matrixlist.append(PAD)\n",
    "        # We concat the blocks\n",
    "        matrix=tr.cat(matrixlist[:-1])\n",
    "        # We shape them as a matrix\n",
    "        matrix=matrix.reshape((self.n,self.n,batchSize))\n",
    "        # We roll the axis to have the batch as first dimention and perform operations on it in parallel\n",
    "        matrix=matrix.permute((2,0,1)) \n",
    "        return matrix\n",
    "\n",
    "#==================================================================================================\n",
    "#--------------------------------------------------------------------------------------------------\n",
    "#==================================================================================================\n",
    "\n",
    "class K_Matrix(nn.Module):\n",
    "    '''\n",
    "    `K_Matrix` is the abstraction for the whole process of fixing the real parameters and apply the matrix. It is responsable of the evolution\n",
    "    in time and act on the Koopman subspace.\n",
    "    '''\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.matrix=customMatrix()\n",
    "\n",
    "    def forward(self,x,Dt):\n",
    "        # We compose the Jordan matrix fixing the real parameters\n",
    "        M=self.matrix(x,Dt)\n",
    "        # We evolve in time applying the matrix product between the point in Koopman subspace and the Jordan matrix\n",
    "        res=M.bmm(x.unsqueeze(-1)).squeeze(-1) # N.B. the matrix is shaped (`batchSize`,`n`,`n`) with `n` the dimension of the Koopman subspace.\n",
    "                                               #      to perform batch matrix multplication we had to tranform the vector in a `n`x 1 matrix \n",
    "                                               #      (`batchSize`,`n`,1). Than we had to squeeze back the result in vectorial form (`batchSize`,`n`)\n",
    "        return res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KOOPMAN(nn.Module):\n",
    "    '''\n",
    "    KOOPMAN Net is the whole composition of encoder, K_matrix (with the matrix in itself and all the auxiliary networks) and decoder\n",
    "    '''\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.ENC=Encoder()\n",
    "        self.K=K_Matrix()\n",
    "        self.DEC=Decoder()\n",
    "    def forward(self,XT: tr.tensor,Dt: float,NShift: int) -> Tuple[tr.tensor,tr.tensor,tr.tensor,tr.tensor]:\n",
    "        '''\n",
    "        The input of the Net is a (`numShift+1`,`batchSize`,`coord`) `XT`, the first dimention indicate time position in the trajectory, the second\n",
    "        the bacht dimension, the third, the geometric dimention of generalized spatial coordinate in the phase space of the experiment. `Dt` is\n",
    "        the time past between two different trajecory points, `numShift` is the number of time-shifts considered (the lenght of the trajectory).\n",
    "        '''\n",
    "        PhiT=self.ENC(XT) # This will encode all the coodinates at all the times\n",
    "        PhiPredT=PhiT[0].unsqueeze(0) # This will be the tensor containing all the prediction made evolving the first point\n",
    "        PhiPredT=PhiPredT.expand((NShift+1,batchSize,coor)) # I expand it to be (`numShift+1`,`batchSize`,{dimension Koopman subspace})\n",
    "        # We evolved temporally the frame and by stored the result in `PhiPredT`, it will contain the predicted trajectory in Koopman subspace from the initial condition\n",
    "        #   at `numShift` subsequent times\n",
    "        for i in range(NShift):\n",
    "            phiOld=PhiPredT[i].clone() # The `clone` method is needed because without it, accessing a tensor subsripting it and assigning it to a variable, is considered\n",
    "                                       # by torch as an inplace operation (probably because of his \"view\" menagement of GPU resources) \n",
    "            phiNew=self.K(phiOld,Dt)\n",
    "            PhiPredT[i+1]=phiNew\n",
    "        YT=self.DEC(PhiPredT) # This will encode all the prediction back in phase space\n",
    "        return XT, YT, PhiT,PhiPredT\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=KOOPMAN()\n",
    "print(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Procedure\n",
    "\n",
    "They initialized each weight matrix W randomly from a uniform distribution in the range $[-s, s]$ for $s = \\frac{1}{\\sqrt{a}}$, where $a$ is the dimension of the input of the layer. Each bias vector $b$ is initialized to 0. The learning rate for the Adam optimizer is 0.001. We also use early stopping; for each model, at the end of training, we resume the step with the lowest validation error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS=100  # Max number of epochs to train\n",
    "patience=20 # If after `patience` epochs the model didn't improved, the training is automatically stopped\n",
    "optim= opt.Adam(params=model.parameters(),lr=lr,weight_decay=lamb_l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping(Exception):\n",
    "    '''\n",
    "    Custom exception to raise in case of stop due to number of epochs in which the model didn't improve greater than `patience`.\n",
    "    '''\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "    \n",
    "\n",
    "\n",
    "class SaveBestModel:\n",
    "    '''\n",
    "    This utility is needed to save the best model (choosen using the one that minimize the loss on the validation dataset) and to check if\n",
    "    any improvement as occurred during last epochs.\n",
    "    `best_valid_loss` is the minimum of the loss found\n",
    "    `best_epoch`      is the epoch at witch the validation was minimal\n",
    "    `patience`        is the maximum number of epochs that we consider the model to have the potential of improving over the last updating\n",
    "    '''\n",
    "    def __init__(self,patience=100, best_vali_loss=float('inf')) -> None: #object initialized with best_loss = +infinite\n",
    "        self.best_vali_loss = best_vali_loss\n",
    "        self.patience=patience\n",
    "        self.best_epoch=0\n",
    "        self._fromLastUpdate=0\n",
    "        \n",
    "    def __call__(\n",
    "        self, current_vali_loss: float, epoch: int,\n",
    "        model: nn.Module, \n",
    "        optimizer: opt.Optimizer,\n",
    "        criterion: Callable[[tr.tensor,tr.tensor],float], \n",
    "        metric: float\n",
    "    ):\n",
    "        if current_vali_loss < self.best_vali_loss:\n",
    "            # Private attribute containing the last epochs in which the model improved\n",
    "            self._fromLastUpdate=0\n",
    "            self.best_vali_loss = current_vali_loss\n",
    "            print(f\"\\nBest validation loss: {self.best_vali_loss}\")\n",
    "            print(f\"\\nSaving best model for epoch: {epoch+1}\\n\")\n",
    "            # method to save a model (the state_dict: a python dictionary object that \n",
    "            # maps each layer to its parameter tensor) and other useful parametrers\n",
    "            # see: https://pytorch.org/tutorials/beginner/saving_loading_models.html\n",
    "            tr.save({\n",
    "                     'epoch': epoch+1,\n",
    "                     'model_state_dict': model.state_dict(),\n",
    "                     'optimizer_state_dict': optimizer.state_dict(),\n",
    "                     'loss': criterion,\n",
    "                     'metric': metric\n",
    "                    },\n",
    "                    'best_model.pth')\n",
    "            self.best_epoch=epoch+1\n",
    "        else:\n",
    "            self._fromLastUpdate+=1\n",
    "\n",
    "        # Trow an exception if model has to stop due to early stopping\n",
    "        if self._fromLastUpdate>self.patience:\n",
    "            raise EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_best_model=SaveBestModel(patience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists containing history during epochs of:\n",
    "h_loss_tr  =[] # loss on train dataset\n",
    "h_metric_tr=[] # metric on train dataset\n",
    "h_loss_vl  =[] # loss on validation dataset\n",
    "h_metric_vl=[] # metric on validation dataset\n",
    "\n",
    "metric.to(device)\n",
    "model=model.to(device)\n",
    "for e in range(EPOCHS):\n",
    "    t0=time.time()\n",
    "    # Put model in train mode\n",
    "    model.train()\n",
    "    lossVal=0.0\n",
    "    metrVal=0.0\n",
    "    nbatch=0\n",
    "    # Loop for each batch in all the train dataset\n",
    "    for x in train:\n",
    "        x=x.to(device).swapaxes(0,1)\n",
    "        nbatch+=1\n",
    "        XT, YT, PhiT,PhiPredT=model(x,Dt,numShift)\n",
    "        l=loss(XT, YT, PhiT,PhiPredT)\n",
    "        m=metric(XT[1],YT[1])\n",
    "        l.backward()\n",
    "        optim.step()\n",
    "        optim.zero_grad()\n",
    "        lossVal+=l.item()\n",
    "        metrVal+=m.item()\n",
    "        \n",
    "    # Normalize the loss and the metric to have the mean value between all the batches\n",
    "    lossVal/=nbatch\n",
    "    metrVal/=nbatch\n",
    "    h_loss_tr.append(lossVal)\n",
    "    h_metric_tr.append(metrVal)\n",
    "\n",
    "    # Put model in evaluation mode\n",
    "    model.eval()\n",
    "    vl_lossVal=0.0\n",
    "    vl_metrVal=0.0\n",
    "    nbatch=0\n",
    "    # Loop for each batch in all the validation dataset\n",
    "    for x in vali:\n",
    "        nbatch+=1\n",
    "        x=x.to(device).swapaxes(0,1)\n",
    "        XT, YT, PhiT,PhiPredT=model(x,Dt,numShift)\n",
    "        l=loss(XT, YT, PhiT,PhiPredT)\n",
    "        m=metric(XT[1],YT[1])\n",
    "        vl_lossVal+=l.item()\n",
    "        vl_metrVal+=m.item()\n",
    "    vl_lossVal/=nbatch\n",
    "    vl_metrVal/=nbatch\n",
    "    h_loss_vl.append(vl_lossVal)\n",
    "    h_metric_vl.append(vl_metrVal)\n",
    "\n",
    "    elapsed_time = time.time()-t0    \n",
    "    print(f\"epoch: {e+1}, time(s): {elapsed_time:.2f}, train loss: {lossVal:.6f}, train metric: {metrVal:.6f}, vali loss: {vl_lossVal:.6f}, vali metric: {vl_metrVal:.6f}\")\n",
    "    try: \n",
    "        save_best_model(vl_lossVal,e,model,optim,metric,metrVal)\n",
    "    except EarlyStopping:\n",
    "        print(f\"Early Stopping occurred at epoch: {e+1}, best validation loss is {save_best_model.best_vali_loss}\")\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch=save_best_model.best_epoch\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(range(1,len(h_loss_tr)+1),   h_loss_tr, color='green', linestyle='-', label='train loss')\n",
    "plt.plot(range(1,len(h_loss_vl)+1),  h_loss_vl, color='blue', linestyle='-', label='validation loss')\n",
    "plt.axvline(best_epoch,color=\"r\",linestyle=\"--\",label=\"best epoch\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(range(1,len(h_metric_tr)+1),  h_metric_tr,  color='green', linestyle='-', label='train metric')\n",
    "plt.plot(range(1,len(h_metric_vl)+1),  h_metric_vl, color='blue', linestyle='-', label='validation metric')\n",
    "plt.axvline(best_epoch,color=\"r\",linestyle=\"--\",label=\"best epoch\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Metric')\n",
    "plt.legend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cpu()\n",
    "metric.cpu()\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "ts_lossVal=0.0\n",
    "ts_metrVal=0.0\n",
    "nbatch=0\n",
    "# Loop for each batch in all the test dataset\n",
    "for x in test:\n",
    "    nbatch+=1\n",
    "    x=x.cpu().swapaxes(0,1)\n",
    "    XT, YT, PhiT,PhiPredT=model(x,Dt,numShift)\n",
    "    l=loss(XT, YT, PhiT,PhiPredT)\n",
    "    m=metric(XT[1],YT[1])\n",
    "    ts_lossVal+=l.item()\n",
    "    ts_metrVal+=m.item()\n",
    "ts_lossVal/=nbatch\n",
    "ts_metrVal/=nbatch\n",
    "print(f\"Loss value on TEST dataset:\\t{ts_lossVal}\\nMetric on TEST dataset:\\t\\t{ts_metrVal}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphs\n",
    "\n",
    "In order to test our model we considered the following plots:\n",
    "\n",
    "1) The correlation $ \\langle \\textbf{x}(k) , \\textbf{x}(k+ m) \\rangle $ at different discrete time steps m (evolution provided by the network) and fixed k and we compared it with the result found with numerical integration.\n",
    "2) $\\textbf{x}_i (k)\\ \\text{vs}\\ \\textbf{x}_j (k)$ at different time steps k (evolution provided by the network)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_corr_m=XT.permute((2,0,1)).cpu().detach().numpy()\n",
    "Y_corr_m=YT.permute((2,0,1)).cpu().detach().numpy()\n",
    "\n",
    "plt.rcParams['text.usetex'] = True\n",
    "\n",
    "fig,axs=plt.subplots(1,3,figsize=(15,5))\n",
    "ax1,ax2,ax3=axs\n",
    "ax1.set_title(r\"Auto correlation of trajectory $\\langle \\textbf{x}(k) , \\textbf{x}(k+ m) \\rangle$\")\n",
    "ax1.set_xlabel(r\"Time-steps difference in frames m\")\n",
    "ax1.set_ylabel(r\"Pearson coefficient\")\n",
    "ax2.set_title(r\"Corr. true and predicted trajectory $\\langle \\textbf{x}(k+m) , \\textbf{y}(k+ m) \\rangle$\")\n",
    "ax2.set_xlabel(r\"Time-steps difference in frames $m$\")\n",
    "ax2.set_ylabel(r\"Pearson coefficient\")\n",
    "ax3.set_title(r\"Auto correlation of predicted trajectory $\\langle \\textbf{y}(k) , \\textbf{y}(k+ m) \\rangle$\")\n",
    "ax3.set_xlabel(r\"Time-steps difference in frames $m$\")\n",
    "ax3.set_ylabel(r\"Pearson coefficient\")\n",
    "\n",
    "for i in range(coor):\n",
    "    X=range(1,len(X_corr_m[i])+1)\n",
    "    Y=[]\n",
    "    for ix in range(len(X)):\n",
    "        Y.append(pearsonr(X_corr_m[i][0],X_corr_m[i][ix])[0])\n",
    "    ax1.plot(X,Y,label=r\"$\\langle x_\"+str(i)+r\"(k), x_\"+str(i)+r\"(k+m) \\rangle$\",marker='.')\n",
    "    Y=[]\n",
    "    for ix in range(len(X)):\n",
    "        Y.append(pearsonr(X_corr_m[i][ix],Y_corr_m[i][ix])[0])\n",
    "    ax2.plot(X,Y,label=r\"$\\langle x_\"+str(i)+r\"(k+m), y_\"+str(i)+r\"(k+m) \\rangle$\",marker='.')\n",
    "    Y=[]\n",
    "    for ix in range(len(X)):\n",
    "        Y.append(pearsonr(Y_corr_m[i][0],Y_corr_m[i][ix])[0])\n",
    "    ax3.plot(X,Y,label=r\"$\\langle y_\"+str(i)+r\"(k), y_\"+str(i)+r\"(k+m) \\rangle$\",marker='.')\n",
    "\n",
    "ax1.legend()\n",
    "ax2.legend()\n",
    "ax3.legend()\n",
    "fig.savefig(\"correlations.png\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAN=np.random.randint(0,len(XT[0].cpu().detach().numpy()))\n",
    "X_traj=XT.permute((1,2,0)).cpu().detach().numpy()[RAN]\n",
    "Y_traj=YT.permute((1,2,0)).cpu().detach().numpy()[RAN]\n",
    "\n",
    "fig,ax=plt.subplots(1,figsize=(5,5))\n",
    "ax.set_title(f\"Trajectory in phase space [initial condition {RAN}]\")\n",
    "ax.set_xlabel(r\"$x_0(t)$\")\n",
    "ax.set_ylabel(r\"$x_1(t)$\")\n",
    "ax.plot(X_traj[0],X_traj[1],label=\"Trajectory\",marker='.')\n",
    "ax.plot(Y_traj[0],Y_traj[1],label=\"Predicted\",marker='.')\n",
    "ax.legend()\n",
    "fig.savefig(\"random_trajectory.png\")\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
